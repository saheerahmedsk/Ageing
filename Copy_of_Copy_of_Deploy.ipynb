{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of Deploy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D10eR-K1uXg"
      },
      "source": [
        "## Please run this notebook in colab or any GPU backend system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX_3cMbKAIwK"
      },
      "source": [
        "%cd /content\n",
        "!mkdir traning_demo\n",
        "!mkdir traning_demo/pre-trained-models\n",
        "!mkdir traning_demo/annotations\n",
        "!mkdir traning_demo/export_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4IyhqFPdyCx"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axPd-0oRITOe"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egsDMFq8OLcZ"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we7Z5YNBOOcS"
      },
      "source": [
        "%cd /content/models/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0duZwjfOUDk"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yvUs-unROUL"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uSRXJ7dRSvb"
      },
      "source": [
        "%cd cocoapi/PythonAPI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub6XmU1TRYLT"
      },
      "source": [
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWeSBPODRZvS"
      },
      "source": [
        "%cp -r pycocotools /content/models/research"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPNe5G_YRdh9"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDaiORV7RmJz"
      },
      "source": [
        "%cd ../.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icv4Duv8RoAz"
      },
      "source": [
        "%cp object_detection/packages/tf2/setup.py ."
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0oEwWDiRqMO"
      },
      "source": [
        "!python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfPZ-fIpRrys"
      },
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha8GDxxFRu3m"
      },
      "source": [
        "%cd /content/traning_demo/pre-trained-models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV8ANeb6jI9T"
      },
      "source": [
        "# !rm -r efficientdet_d0_coco17_tpu-32"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zZcKeyDcpXB"
      },
      "source": [
        "# https://drive.google.com/file/d/1C8J5g7zRr3rfbr9db5Q8HCOfXglOG7Kb/view?usp=sharing\n",
        "# Efficientdet pretrained model with wrinkles and darkspots\n",
        "# Comment this line if you want try with custom one\n",
        "\n",
        "!gdown --id 1C8J5g7zRr3rfbr9db5Q8HCOfXglOG7Kb\n",
        "!unzip efdnet_2C.zip\n",
        "!mv /content/traning_demo/pre-trained-models/content/traning_demo/export_model /content/traning_demo/pre-trained-models\n",
        "!mv /content/traning_demo/pre-trained-models/export_model darkspots\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# https://drive.google.com/file/d/1-0zzdLi3bGk8zlGkAyBhQQPtf_bIuMep/view?usp=sharing\n",
        "# Wrinkles\n",
        "!gdown --id 1-0zzdLi3bGk8zlGkAyBhQQPtf_bIuMep\n",
        "!unzip efdnet.zip\n",
        "!mv /content/traning_demo/pre-trained-models/content/traning_demo/export_model /content/traning_demo/pre-trained-models\n",
        "!mv /content/traning_demo/pre-trained-models/export_model Wrinkles\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# https://drive.google.com/file/d/1zvHrTZBTLJVsGixF7us2ByPmiGgb3IOj/view?usp=sharing\n",
        "# Darkspots\n",
        "# !gdown --id 1zvHrTZBTLJVsGixF7us2ByPmiGgb3IOj\n",
        "# !unzip darkspots.zip\n",
        "# !mv /content/traning_demo/pre-trained-models/content/fine_tuned_model /content/traning_demo/pre-trained-models\n",
        "# !mv /content/traning_demo/pre-trained-models/fine_tuned_model /content/traning_demo/pre-trained-models/darkspots\n",
        "\n",
        "\n",
        "# Uncomment this if you want to train from scratch\n",
        "# !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "# !tar -xf /content/traning_demo/pre-trained-models/efficientdet_d0_coco17_tpu-32.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpMwBPAndjXU"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BnQ4u36mbK-"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4O4qw398e9m"
      },
      "source": [
        "# rm -r /content/traning_demo/dataset\n",
        "!rm -r /content/traning_demo/export_model/\n",
        "!mkdir export_model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LLUhyyjkUi0"
      },
      "source": [
        "# https://drive.google.com/file/d/1m3gm3tKGhTQ9a_i_cLD_SS005XMX7ZM_/view?usp=sharing\n",
        "# Download the dataset\n",
        "\n",
        "# !gdown --id 1m3gm3tKGhTQ9a_i_cLD_SS005XMX7ZM_\n",
        "# !unzip /content/traning_demo/dataset.zip"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWCame50iaeD"
      },
      "source": [
        "# https://drive.google.com/file/d/1C1vNYIgXbxhN1p4NgpKX_BU15DHGOQyw/view?usp=sharing\n",
        "# Download required python files\n",
        "!gdown --id 1C1vNYIgXbxhN1p4NgpKX_BU15DHGOQyw\n",
        "!unzip python_files.zip\n",
        "!mv label_map.pbtxt /content/traning_demo/annotations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKIR5ZFXntyv"
      },
      "source": [
        "# Create train data:\n",
        "# !python /content/traning_demo/generate_tfrecord.py -x /content/traning_demo/dataset/train -l /content/traning_demo/annotations/label_map.pbtxt -o /content/traning_demo/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "# !python /content/traning_demo/generate_tfrecord.py -x /content/traning_demo/dataset/test -l /content/traning_demo/annotations/label_map.pbtxt -o/content/traning_demo/annotations/test.record"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHeQ9LI3rHJ5"
      },
      "source": [
        "!mkdir my_model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl1efAvFoPac"
      },
      "source": [
        "# !cp /content/traning_demo/pre-trained-models/efficientdet_d0_coco17_tpu-32/pipeline.config /content/traning_demo/my_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34PQkbwj_DBp"
      },
      "source": [
        "%cd /content/traning_demo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByvrPYqxyjvx"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xSI21Knn-DB"
      },
      "source": [
        "# !rm -r /content/traning_demo/export_model\n",
        "# !mkdir export_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwhFpKveuUua"
      },
      "source": [
        "# Train \n",
        "# %%time\n",
        "# !python /content/traning_demo/model_main_tf2.py --model_dir=/content/traning_demo/my_model --pipeline_config_path=/content/traning_demo/my_model/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMQgb-tN3cpW"
      },
      "source": [
        "# Exporting model\n",
        "# %%time\n",
        "# !python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/traning_demo/my_model/pipeline.config --trained_checkpoint_dir /content/traning_demo/my_model --output_directory=/content/traning_demo/export_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoCKXlzSwQKO"
      },
      "source": [
        "# !cp -r /content/traning_demo/pre-trained-models/efficientdet_d0_coco17_tpu-32/. /content/traning_demo/export_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5WCifioLcZn"
      },
      "source": [
        "%%time\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR_WRINKLES = '/content/traning_demo/pre-trained-models/Wrinkles'\n",
        "\n",
        "MIN_CONF_THRESH = float(0.10)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "PATH_TO_SAVED_MODEL_WRINKLES = PATH_TO_MODEL_DIR_WRINKLES + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn_wrinkles = tf.saved_model.load(PATH_TO_SAVED_MODEL_WRINKLES)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6S0MbQcmlog"
      },
      "source": [
        "PATH_TO_MODEL_DIR_DARKSPOTS = '/content/traning_demo/pre-trained-models/darkspots'\n",
        "\n",
        "MIN_CONF_THRESH = float(0.10)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "PATH_TO_SAVED_MODEL_DARKSPOTS = PATH_TO_MODEL_DIR_DARKSPOTS + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn_darkspots = tf.saved_model.load(PATH_TO_SAVED_MODEL_DARKSPOTS)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK0uqMAIPAI7"
      },
      "source": [
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# import matplotlib.pyplot as plt\n",
        "# import warnings\n",
        "# import cv2\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# # PROVIDE PATH TO IMAGE DIRECTORY\n",
        "# IMAGE_PATHS = '/content/traning_demo/dataset/test/5f4278a310117792c164ed4d3e20f586.jpg'\n",
        "\n",
        "# # PROVIDE PATH TO LABEL MAP\n",
        "# PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "# # LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "# category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "#                                                                     use_display_name=True)\n",
        "\n",
        "\n",
        "# print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "# image = cv2.imread(IMAGE_PATHS)\n",
        "# image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "# image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "\n",
        "# input_tensor = tf.convert_to_tensor(image)\n",
        "\n",
        "# input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "\n",
        "# detections = detect_fn(input_tensor)\n",
        "\n",
        "# num_detections = int(detections.pop('num_detections'))\n",
        "# detections = {key: value[0, :num_detections].numpy()\n",
        "#                for key, value in detections.items()}\n",
        "# detections['num_detections'] = num_detections\n",
        "\n",
        "# detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "# image_with_detections = image.copy()\n",
        "\n",
        "# viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "#       image_with_detections,\n",
        "#       detections['detection_boxes'],\n",
        "#       detections['detection_classes'],\n",
        "#       detections['detection_scores'],\n",
        "#       category_index,\n",
        "#       use_normalized_coordinates=True,\n",
        "#       max_boxes_to_draw=200,\n",
        "#       min_score_thresh=0.4,\n",
        "#       agnostic_mode=False)\n",
        "\n",
        "# print('Done')\n",
        "# # DISPLAYS OUTPUT IMAGE\n",
        "# cv2_imshow(image_with_detections)\n",
        "# # cv2.imwrite(\"Test.jpg\", image_with_detections)\n",
        "# # CLOSES WINDOW ONCE KEY IS PRESSED"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0cwo-bPU1ur"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_dE7-FxJoZ1"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvvz6PbJBuV7"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlcP-buQc-9d"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FURMCaDrDupp"
      },
      "source": [
        "# https://drive.google.com/file/d/1iWvskjmJD4Xr1x2NtV0TYJm116lh1MHq/view?usp=sharing\n",
        "!gdown --id 1iWvskjmJD4Xr1x2NtV0TYJm116lh1MHq\n",
        "!unzip webpage.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDJ8qG5yCVt8"
      },
      "source": [
        "# https://drive.google.com/file/d/1fMsK5T1S0rkzzth5wVcMHDbY4H5gYZTA/view?usp=sharing\n",
        "# Efficientnet model. For pluffy eyes\n",
        "!gdown --id 1fMsK5T1S0rkzzth5wVcMHDbY4H5gYZTA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BO-q_Cov1po"
      },
      "source": [
        "# https://drive.google.com/file/d/1OzT-szWYdMFQIVX-KQ7PMLhjuSdgAf7Z/view?usp=sharing\n",
        "# !gdown --id 1OzT-szWYdMFQIVX-KQ7PMLhjuSdgAf7Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acCGDq9IeffD"
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from flask import Flask, flash, request, redirect, url_for, render_template\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "\n",
        "\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import dlib\n",
        "import glob\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti68Nzz9vM8y"
      },
      "source": [
        "# predictor_path = 'shape_predictor_81_face_landmarks.dat'\n",
        "\n",
        "\n",
        "# def face_extract(path):\n",
        "\n",
        "#     img=cv2.imread(path)\n",
        "\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     hog_face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "#     detector = dlib.get_frontal_face_detector()\n",
        "#     predictor = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "#     dets = detector(img, 0)\n",
        "\n",
        "#     facePoints = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 78, 74, 79, 73, 72, 80, 71, 70, 69, 68, 76, 75, 77, 0]\n",
        "\n",
        "#     for k, d in enumerate(dets):\n",
        "#         shape = predictor(img, d)\n",
        "#         landmarks = np.matrix([[p.x, p.y] for p in shape.parts()])\n",
        "\n",
        "#         mask = np.zeros(img.shape[:2], np.uint8)\n",
        "\n",
        "#         face = np.array([ [shape.parts()[num].x, shape.parts()[num].y] for num in facePoints ])\n",
        "\n",
        "#         cv2.drawContours(mask, [np.array(face)], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
        "\n",
        "#         dst = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "#         plt.figure(figsize=(10, 10))\n",
        "#         plt.imshow(dst)\n",
        "#         return dst, img"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9otaL9cM9Vw"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import cv2\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def effecientDet_wrinkles(path):\n",
        "\n",
        "  # IMAGE_PATHS = path\n",
        "\n",
        "  PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "  category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "\n",
        "  print('Running inference... ', end='')\n",
        "\n",
        "  # image = cv2.imread(IMAGE_PATHS)\n",
        "  image = path\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "\n",
        "  detections = detect_fn_wrinkles(input_tensor)\n",
        "\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "  image_with_detections = image.copy()\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=0.4,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "  return image_with_detections\n",
        "\n",
        "def effecientDet_darkspots(path):\n",
        "\n",
        "  # IMAGE_PATHS = path\n",
        "\n",
        "  PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "  category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "\n",
        "  print('Running inference... ', end='')\n",
        "\n",
        "  # image = cv2.imread(IMAGE_PATHS)\n",
        "  image = path\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "\n",
        "  detections = detect_fn_darkspots(input_tensor)\n",
        "\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "  image_with_detections = image.copy()\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=0.4,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "  return image_with_detections"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW8KLGQlqt3J"
      },
      "source": [
        "# img = effecientDet_wrinkles()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fyi4M29rKwx"
      },
      "source": [
        "# file_path = '/content/54196f0c2590c2a308ba2233b31552bf.jpg'\n",
        "# img, orgImg = face_extract(file_path)\n",
        "# plt.imshow(img)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# img = effecientDet_wrinkles(img)\n",
        "# cv2_imshow(img)\n",
        "# img = effecientDet_darkspots(img)\n",
        "# cv2_imshow(img)\n",
        "\n",
        "# left_eye, right_eye, eye_points, img = eyes(img)\n",
        "# img, percent = predict_puffyeyes(left_eye, right_eye, eye_points, img, orgImg)\n",
        "# # plt.imshow(img)\n",
        "# # plt.show()\n",
        "# cv2.imwrite(file_path, img)\n",
        "# print(percent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt4-vxvmecMt"
      },
      "source": [
        "model=load_model('efficientnet.h5')\n",
        "eye_cascade=cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "def eyes(path):\n",
        "\t# img=cv2.imread(path)\n",
        "\timg = path.copy()\n",
        "\teye_rects=eye_cascade.detectMultiScale(img)\n",
        "\teye_points=[]\n",
        "\tfor x,y,w,h in eye_rects:\n",
        "\t\teye_points.append([x,y,w,h])\n",
        "\tx1=eye_points[0][0]\n",
        "\ty1=eye_points[0][1]\n",
        "\tx2=eye_points[0][0]+eye_points[0][2]\n",
        "\ty2=eye_points[0][1]+eye_points[0][3]+30\n",
        "\tleft_eye=img[y1:y2,x1:x2]\n",
        "\tleft_eye=Image.fromarray(left_eye)\n",
        "\tleft_eye=left_eye.resize((224,224))\n",
        "\tleft_eye=asarray(left_eye)\n",
        "\tif len(eye_points)>1:\n",
        "\t\tx1=eye_points[1][0]\n",
        "\t\ty1=eye_points[1][1]\n",
        "\t\tx2=eye_points[1][0]+eye_points[1][2]  \n",
        "\t\ty2=eye_points[1][1]+eye_points[1][3]+30\n",
        "\t\tright_eye=img[y1:y2,x1:x2]\n",
        "\t\tright_eye=Image.fromarray(right_eye)\n",
        "\t\tright_eye=right_eye.resize((224,224))\n",
        "\t\tright_eye=asarray(right_eye)\n",
        "\telse:\n",
        "\t\tright_eye=0\n",
        "\treturn left_eye, right_eye, eye_points, img\n",
        "\n",
        "def predict_puffyeyes(left_eye,right_eye,l1,img, orgImg):\n",
        "\ttest_image=np.expand_dims(left_eye,axis=0)\n",
        "\tresult=model.predict(test_image)\n",
        "\ttempImg = orgImg.copy()\n",
        "\tif result[0][0]>result[0][1]:\n",
        "\t\treturn orgImg, \"No puffy eyes present\"\n",
        "\telse:\n",
        "\t\t#print('left puffy eyes percentage',result[0][1]*100,'%')\n",
        "\t\tb=round(result[0][1]*100,2)\n",
        "\t\tx,y,w,h=l1[0]\n",
        "\t\tcv2.rectangle(tempImg, (x,y), (x+w,y+h+30), (0,255,255), 2)\n",
        "\t\tcv2.putText(tempImg,'Puffy eyes',(x,y+h+15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,25), 1, cv2.LINE_AA)\n",
        "\tif type(right_eye)!=int:\n",
        "\t\ttest_image=np.expand_dims(right_eye,axis=0)\n",
        "\t\tresult=model.predict(test_image)\n",
        "\t\tif result[0][0]>result[0][1]:\n",
        "\t\t\treturn orgImg, \"No puffy eyes present\"\n",
        "\t\telse:\n",
        "\t\t\t#print('right puffy eyes percentage',result[0][1]*100,'%')\n",
        "\t\t\ta=round(result[0][1]*100,1)\n",
        "\t\t\tx,y,w,h=l1[1]\n",
        "\t\t\tcv2.rectangle(tempImg, (x,y), (x+w,y+h+30), (0,255,255), 2)\n",
        "\t\t\tcv2.putText(tempImg,'Puffy eyes',(x,y+h+15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,25), 1, cv2.LINE_AA)\n",
        "\t\t\treturn tempImg, \"\"\n",
        "\treturn orgImg, \"\""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oV_gG4ZM9OU"
      },
      "source": [
        "# img, orgImg = face_extract('/content/traning_demo/dataset/test/darkspots(41).jpg')\n",
        "# left_eye, right_eye, eye_points, img = eyes(img)\n",
        "# img, percent = predict_puffyeyes(left_eye, right_eye, eye_points, img, orgImg)\n",
        "# img = effecientDet(img)\n",
        "# print(percent)\n",
        "# plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2oBjxDVM9FM"
      },
      "source": [
        "def load_img(path) :\n",
        "  img=cv2.imread(path)\n",
        "  return img"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX_WbfuYGDOG"
      },
      "source": [
        "\n",
        "UPLOAD_FOLDER = 'static/uploads/'\n",
        "\n",
        "app = Flask(__name__, template_folder='templates')\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "run_with_ngrok(app)\n",
        "\n",
        "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg', 'gif'])\n",
        "\n",
        "def allowed_file(filename):\n",
        "\treturn '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\t\n",
        "@app.route('/')\n",
        "def upload_form():\n",
        "\treturn render_template('index.html')\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def upload_image():\n",
        "\tprint(\"File uploaded\")\n",
        "\tif 'file' not in request.files:\n",
        "\t\treturn redirect(request.url)\n",
        "\tfile = request.files['file']\n",
        "\tif file.filename == '':\n",
        "\t\tflash('No image selected for uploading')\n",
        "\t\treturn redirect(request.url)\n",
        "\tif file and allowed_file(file.filename):\n",
        "\t\tfilename = secure_filename(file.filename)\n",
        "\t\t\n",
        "\n",
        "\t\tfile_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "\t\tfile.save(file_path)\n",
        "\t\tprint('upload_image filename: ' + filename)\n",
        "\t\tprint(file_path)\n",
        "\t\tpercent = \"\"\n",
        "\t\ttry:\n",
        "\t\t\t\t# img, orgImg = face_extract(file_path)\n",
        "\t\t\t\timg = load_img(file_path)\n",
        "\t\t\t\torgImg = img\n",
        "\n",
        "\t\t\t\timg = effecientDet_wrinkles(img)\n",
        "\t\t\t\t# cv2_imshow(img)\n",
        "\t\t\t\timg = effecientDet_darkspots(img)\n",
        "\t\t\t\t# cv2_imshow(img)\n",
        "\t\t\t\torgImg = img.copy()\n",
        "\t\t\t\tleft_eye, right_eye, eye_points, img = eyes(img)    \n",
        "\t\t\t\timg, percent = predict_puffyeyes(left_eye, right_eye, eye_points, img, img)\n",
        "\t\t\t\t# cv2_imshow(img)\n",
        "\n",
        "\t\t\t\tcv2.imwrite(file_path, img)\n",
        "\t\t\t\tprint(percent)\n",
        "\n",
        "\t\t\t\treturn render_template('result.html', filename=filename, eyes=percent)\n",
        "\t\texcept :\n",
        "\t\t\t\tprint(\"exception in eyes\")\n",
        "\t\t\t\tcv2.imwrite(file_path, img)\n",
        "\t\t\t\treturn render_template('result.html', filename=filename, eyes=\"No puffy eyes present\")\n",
        "\telse:\n",
        "\t\t# flash('Allowed image types are -> png, jpg, jpeg, gif')\n",
        "\t\treturn redirect(request.url)\n",
        "\n",
        "@app.route('/display/<filename>')\n",
        "def display_image(filename):\n",
        "\tprint('display_image filename: ' + filename)\n",
        "\treturn redirect(url_for('static', filename='uploads/' + filename), code=301)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tapp.run()"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op0UNzia1SXY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}